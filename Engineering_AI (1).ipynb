{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "SYsdbngv2gx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers sentence-transformers scikit-learn"
      ],
      "metadata": {
        "id": "bYGC0cIvnXQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    chunks = re.split(r\"(?=\\d{5})\", text.strip())\n",
        "    clean_chunks = [re.sub(r'\\n+', ' ', chunk.strip()) for chunk in chunks if chunk.strip()]\n",
        "    return clean_chunks\n",
        "\n",
        "def load_and_preprocess(filepath):\n",
        "    with open(filepath, 'r') as file:\n",
        "        text = file.read()\n",
        "    chunks = preprocess_text(text)\n",
        "    return chunks\n",
        "\n",
        "def convert_to_vectors(chunks):\n",
        "    vectors = model.encode(chunks)\n",
        "    return vectors\n",
        "\n",
        "def save_vectors_to_json(chunks, vectors, output_json):\n",
        "    data = [{'chunk': chunk, 'vector': vector.tolist()} for chunk, vector in zip(chunks, vectors)]\n",
        "    with open(output_json, 'w') as json_file:\n",
        "        json.dump(data, json_file)\n",
        "\n",
        "chunks = load_and_preprocess('/content/Engineering.txt')\n",
        "vectors = convert_to_vectors(chunks)\n",
        "\n",
        "save_vectors_to_json(chunks, vectors, 'college_data_vectors.json')\n"
      ],
      "metadata": {
        "id": "iqJZ9xp_ovKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def load_vectors_from_json(input_json):\n",
        "    with open(input_json, 'r') as json_file:\n",
        "        data = json.load(json_file)\n",
        "    chunks = [item['chunk'] for item in data]\n",
        "    vectors = [np.array(item['vector']) for item in data]\n",
        "    return chunks, np.array(vectors)\n",
        "\n",
        "# Find the most similar chunk\n",
        "def find_similar_chunk(query, chunks, vectors, top_n=5):\n",
        "    # Convert the query to a vector\n",
        "    query_vector = model.encode([query])[0]\n",
        "\n",
        "    # Calculate cosine similarity between the query vector and all text vectors\n",
        "    similarities = cosine_similarity([query_vector], vectors)[0]\n",
        "\n",
        "    # Get the indices of the top N most similar chunks\n",
        "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
        "\n",
        "    # Return the most similar chunks\n",
        "    similar_chunks = [(chunks[i], similarities[i]) for i in top_indices]\n",
        "    return similar_chunks\n",
        "\n",
        "chunks, vectors = load_vectors_from_json('college_data_vectors.json')"
      ],
      "metadata": {
        "id": "IVb-uGM7o2oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-GdA7RJDIKTQ3xW-1NdmctgWB_4wq6VGozLoom4OIZDT3BlbkFJRvG4FaTvqMRtoIk9hucASYIFRdlUxFjYfPkKoeKdgA\""
      ],
      "metadata": {
        "id": "ZRLWyYxctyr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def generate_text(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model='gpt-3.5-turbo',\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "while :\n",
        "  query = input()\n",
        "  if query not in ['exit','Exit']:\n",
        "    similar_chunks = find_similar_chunk(query, chunks, vectors)\n",
        "    print(f\"Query: {query}\\n\")\n",
        "\n",
        "    prompt = str(similar_chunks)+\"using this data answer this query\"+query\n",
        "    generated_text = generate_text(prompt)\n",
        "    print(generated_text)"
      ],
      "metadata": {
        "id": "jWlcOx3pqEZc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}